# Help-BigData

## **ETL** (Extract/extração, Transform/transformação e Load/carregamento)
As três etapas do processo de gestão de dados.


## Data Lake
O Data Lake é o repositório perfeito para quem precisa abrigar qualquer tipo de dados em qualquer escala. Dashboards, dados em tempo real, analytics, planilhas, informações de machine learning… enfim. Não há restrições para a ferramenta.

Por isso o nome “Lago de Dados”. Para abrigar informações no Data Lake, pode-se dispensar, inclusive, a etapa de tratamento de dados, já que a proposta de quem o utiliza é abrigar e ter acesso a um número elevadíssimo de dados brutos de categorias diferentes em um só lugar.


## Data Warehouse (DW)
Ao contrário do aglomerado de informações de formatos e tamanhos diferentes, o Data Warehouse é um espaço dedicado a receber dados tratados, padronizados e higienizados. A proposta do DW é oferecer visões organizadas que permitam aos profissionais tomar decisões mais embasadas sobre determinada situação. Para abrigar qualquer informação em um DW, é fundamental que elas tenham passado pelo processo de tratamento, diferentemente do Data Lake.


## Cluster
Cluster é um grupo de servidores/máquinas que funcionam como um sistema único. Isso permite alguns benefícios como:
1. Alta disponibilidade
2. Balanceamento de carga
3. Processamento paralelo
4. Escalabilidade horizontal


## Hadoop 
O Hadoop é um sistema distribuído de arquivos. Ele lida com arquivos em um cluster.
Ele é composto por dois componentes principais:

**1. HDFS**  
Sistema Distribuído de Arquivos.

**2. Map Reduce**  
Framework/mecanismo distribuído de processamento de dados que transforma a grande massa de dados em dados menores e estruturados.






<br>
<br>

### Referências:
<https://www.predicta.net/blog/post/2019/03/20/data-lake-x-data-warehouse-entenda-a-diferenca/>
<https://www.youtube.com/watch?v=qX5edsUWadE>

